/* tslint:disable */
/* eslint-disable */
/**
 * Overmind Backend
 * No description provided (generated by Openapi Generator https://github.com/openapitools/openapi-generator)
 *
 * The version of the OpenAPI document: 0.1.0
 * 
 *
 * NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * https://openapi-generator.tech
 * Do not edit the class manually.
 */


import * as runtime from '../runtime';
import type {
  HTTPValidationError,
  SpanFeedbackRequest,
} from '../models/index';
import {
    HTTPValidationErrorFromJSON,
    HTTPValidationErrorToJSON,
    SpanFeedbackRequestFromJSON,
    SpanFeedbackRequestToJSON,
} from '../models/index';

export interface EvaluateSpansApiV1SpansEvaluatePostRequest {
    requestBody: Array<string | null>;
    useCache?: boolean;
}

export interface SubmitSpanFeedbackApiV1SpansSpanIdFeedbackPatchRequest {
    spanId: string;
    spanFeedbackRequest: SpanFeedbackRequest;
    useCache?: boolean;
}

/**
 * 
 */
export class SpansApi extends runtime.BaseAPI {

    /**
     * Evaluate multiple spans based on their linked prompt template criteria.  The endpoint will: 1. Fetch the prompt template linked to these spans 2. Use the evaluation_criteria from the prompt (if exists) 3. Auto-generate criteria if the prompt doesn\'t have any (using first 10 spans)  Criteria is always fetched from the prompt table and cannot be provided directly. Stores correctness score in each span\'s feedback_score field.  This creates a JUDGE_SCORING job that will be executed by the job reconciler.
     * Evaluate Spans
     */
    async evaluateSpansApiV1SpansEvaluatePostRaw(requestParameters: EvaluateSpansApiV1SpansEvaluatePostRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<any>> {
        if (requestParameters['requestBody'] == null) {
            throw new runtime.RequiredError(
                'requestBody',
                'Required parameter "requestBody" was null or undefined when calling evaluateSpansApiV1SpansEvaluatePost().'
            );
        }

        const queryParameters: any = {};

        if (requestParameters['useCache'] != null) {
            queryParameters['use_cache'] = requestParameters['useCache'];
        }

        const headerParameters: runtime.HTTPHeaders = {};

        headerParameters['Content-Type'] = 'application/json';

        if (this.configuration && this.configuration.accessToken) {
            // oauth required
            headerParameters["Authorization"] = await this.configuration.accessToken("OAuth2PasswordBearer", []);
        }


        let urlPath = `/api/v1/spans/evaluate`;

        const response = await this.request({
            path: urlPath,
            method: 'POST',
            headers: headerParameters,
            query: queryParameters,
            body: requestParameters['requestBody'],
        }, initOverrides);

        if (this.isJsonMime(response.headers.get('content-type'))) {
            return new runtime.JSONApiResponse<any>(response);
        } else {
            return new runtime.TextApiResponse(response) as any;
        }
    }

    /**
     * Evaluate multiple spans based on their linked prompt template criteria.  The endpoint will: 1. Fetch the prompt template linked to these spans 2. Use the evaluation_criteria from the prompt (if exists) 3. Auto-generate criteria if the prompt doesn\'t have any (using first 10 spans)  Criteria is always fetched from the prompt table and cannot be provided directly. Stores correctness score in each span\'s feedback_score field.  This creates a JUDGE_SCORING job that will be executed by the job reconciler.
     * Evaluate Spans
     */
    async evaluateSpansApiV1SpansEvaluatePost(requestParameters: EvaluateSpansApiV1SpansEvaluatePostRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<any> {
        const response = await this.evaluateSpansApiV1SpansEvaluatePostRaw(requestParameters, initOverrides);
        return await response.value();
    }

    /**
     * Submit user feedback for a span - either on Overmind Judge scoring or Agent output.  Feedback is stored in the span\'s feedback_score field: - judge_feedback: { rating, text } - used to adjust template criteria - agent_feedback: { rating, text } - used alongside judge score in prompt tuning
     * Submit Span Feedback
     */
    async submitSpanFeedbackApiV1SpansSpanIdFeedbackPatchRaw(requestParameters: SubmitSpanFeedbackApiV1SpansSpanIdFeedbackPatchRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<any>> {
        if (requestParameters['spanId'] == null) {
            throw new runtime.RequiredError(
                'spanId',
                'Required parameter "spanId" was null or undefined when calling submitSpanFeedbackApiV1SpansSpanIdFeedbackPatch().'
            );
        }

        if (requestParameters['spanFeedbackRequest'] == null) {
            throw new runtime.RequiredError(
                'spanFeedbackRequest',
                'Required parameter "spanFeedbackRequest" was null or undefined when calling submitSpanFeedbackApiV1SpansSpanIdFeedbackPatch().'
            );
        }

        const queryParameters: any = {};

        if (requestParameters['useCache'] != null) {
            queryParameters['use_cache'] = requestParameters['useCache'];
        }

        const headerParameters: runtime.HTTPHeaders = {};

        headerParameters['Content-Type'] = 'application/json';

        if (this.configuration && this.configuration.accessToken) {
            // oauth required
            headerParameters["Authorization"] = await this.configuration.accessToken("OAuth2PasswordBearer", []);
        }


        let urlPath = `/api/v1/spans/{span_id}/feedback`;
        urlPath = urlPath.replace(`{${"span_id"}}`, encodeURIComponent(String(requestParameters['spanId'])));

        const response = await this.request({
            path: urlPath,
            method: 'PATCH',
            headers: headerParameters,
            query: queryParameters,
            body: SpanFeedbackRequestToJSON(requestParameters['spanFeedbackRequest']),
        }, initOverrides);

        if (this.isJsonMime(response.headers.get('content-type'))) {
            return new runtime.JSONApiResponse<any>(response);
        } else {
            return new runtime.TextApiResponse(response) as any;
        }
    }

    /**
     * Submit user feedback for a span - either on Overmind Judge scoring or Agent output.  Feedback is stored in the span\'s feedback_score field: - judge_feedback: { rating, text } - used to adjust template criteria - agent_feedback: { rating, text } - used alongside judge score in prompt tuning
     * Submit Span Feedback
     */
    async submitSpanFeedbackApiV1SpansSpanIdFeedbackPatch(requestParameters: SubmitSpanFeedbackApiV1SpansSpanIdFeedbackPatchRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<any> {
        const response = await this.submitSpanFeedbackApiV1SpansSpanIdFeedbackPatchRaw(requestParameters, initOverrides);
        return await response.value();
    }

}
